{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ed319-f535-40db-ba5f-c9438346acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2\n",
    "Bernoulli Naive Bayes uses binary features (presence/absence), while Multinomial Naive Bayes uses feature counts or frequencies. \n",
    "The former is suited for binary data, and the latter for count data.\n",
    "\n",
    "### Q3\n",
    "Bernoulli Naive Bayes typically treats missing values as feature absences (0), assuming missing data indicates the absence of a feature.\n",
    "\n",
    "### Q4\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification, as it models each class with a Gaussian distribution and applies the \n",
    "Naive Bayes algorithm to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7cf841-09ee-49db-b013-cb377c7d3d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that an employee is a smoker given that they use the health insurance plan: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_H = 0.7  # 70% of employees use the health insurance plan\n",
    "P_S_given_H = 0.4  # 40% of employees who use the plan are smokers\n",
    "\n",
    "# Calculate P(S|H)\n",
    "P_S_given_H = P_S_given_H\n",
    "\n",
    "print(\"Probability that an employee is a smoker given that they use the health insurance plan:\", P_S_given_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccd9ad-9aa2-488d-a8c4-c0018edec8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code that uses cross-validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe950ea7-cf0d-45dc-89a3-7e0576c55e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544b8ff7-bb12-4d85-a436-0fee57b914b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe794133-4b62-4601-8da6-2bc0f895ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spambase dataset form UCI \n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e922ecc3-eef9-43cc-a307-1b035c67ccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e6ccb5-b1d8-4e18-9006-53f9ba4a28ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4600 non-null   float64\n",
      " 1   0.64    4600 non-null   float64\n",
      " 2   0.64.1  4600 non-null   float64\n",
      " 3   0.1     4600 non-null   float64\n",
      " 4   0.32    4600 non-null   float64\n",
      " 5   0.2     4600 non-null   float64\n",
      " 6   0.3     4600 non-null   float64\n",
      " 7   0.4     4600 non-null   float64\n",
      " 8   0.5     4600 non-null   float64\n",
      " 9   0.6     4600 non-null   float64\n",
      " 10  0.7     4600 non-null   float64\n",
      " 11  0.64.2  4600 non-null   float64\n",
      " 12  0.8     4600 non-null   float64\n",
      " 13  0.9     4600 non-null   float64\n",
      " 14  0.10    4600 non-null   float64\n",
      " 15  0.32.1  4600 non-null   float64\n",
      " 16  0.11    4600 non-null   float64\n",
      " 17  1.29    4600 non-null   float64\n",
      " 18  1.93    4600 non-null   float64\n",
      " 19  0.12    4600 non-null   float64\n",
      " 20  0.96    4600 non-null   float64\n",
      " 21  0.13    4600 non-null   float64\n",
      " 22  0.14    4600 non-null   float64\n",
      " 23  0.15    4600 non-null   float64\n",
      " 24  0.16    4600 non-null   float64\n",
      " 25  0.17    4600 non-null   float64\n",
      " 26  0.18    4600 non-null   float64\n",
      " 27  0.19    4600 non-null   float64\n",
      " 28  0.20    4600 non-null   float64\n",
      " 29  0.21    4600 non-null   float64\n",
      " 30  0.22    4600 non-null   float64\n",
      " 31  0.23    4600 non-null   float64\n",
      " 32  0.24    4600 non-null   float64\n",
      " 33  0.25    4600 non-null   float64\n",
      " 34  0.26    4600 non-null   float64\n",
      " 35  0.27    4600 non-null   float64\n",
      " 36  0.28    4600 non-null   float64\n",
      " 37  0.29    4600 non-null   float64\n",
      " 38  0.30    4600 non-null   float64\n",
      " 39  0.31    4600 non-null   float64\n",
      " 40  0.33    4600 non-null   float64\n",
      " 41  0.34    4600 non-null   float64\n",
      " 42  0.35    4600 non-null   float64\n",
      " 43  0.36    4600 non-null   float64\n",
      " 44  0.37    4600 non-null   float64\n",
      " 45  0.38    4600 non-null   float64\n",
      " 46  0.39    4600 non-null   float64\n",
      " 47  0.40    4600 non-null   float64\n",
      " 48  0.41    4600 non-null   float64\n",
      " 49  0.42    4600 non-null   float64\n",
      " 50  0.43    4600 non-null   float64\n",
      " 51  0.778   4600 non-null   float64\n",
      " 52  0.44    4600 non-null   float64\n",
      " 53  0.45    4600 non-null   float64\n",
      " 54  3.756   4600 non-null   float64\n",
      " 55  61      4600 non-null   int64  \n",
      " 56  278     4600 non-null   int64  \n",
      " 57  1       4600 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaea6749-8b7f-429c-a70f-83b8353569ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104576</td>\n",
       "      <td>0.212922</td>\n",
       "      <td>0.280578</td>\n",
       "      <td>0.065439</td>\n",
       "      <td>0.312222</td>\n",
       "      <td>0.095922</td>\n",
       "      <td>0.114233</td>\n",
       "      <td>0.105317</td>\n",
       "      <td>0.090087</td>\n",
       "      <td>0.239465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038583</td>\n",
       "      <td>0.139061</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.268960</td>\n",
       "      <td>0.075827</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>5.191827</td>\n",
       "      <td>52.170870</td>\n",
       "      <td>283.290435</td>\n",
       "      <td>0.393913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305387</td>\n",
       "      <td>1.290700</td>\n",
       "      <td>0.504170</td>\n",
       "      <td>1.395303</td>\n",
       "      <td>0.672586</td>\n",
       "      <td>0.273850</td>\n",
       "      <td>0.391480</td>\n",
       "      <td>0.401112</td>\n",
       "      <td>0.278643</td>\n",
       "      <td>0.644816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243497</td>\n",
       "      <td>0.270377</td>\n",
       "      <td>0.109406</td>\n",
       "      <td>0.815726</td>\n",
       "      <td>0.245906</td>\n",
       "      <td>0.429388</td>\n",
       "      <td>31.732891</td>\n",
       "      <td>194.912453</td>\n",
       "      <td>606.413764</td>\n",
       "      <td>0.488669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.275500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314250</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.705250</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>265.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         0.64       0.64.1          0.1         0.32  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n",
       "mean      0.104576     0.212922     0.280578     0.065439     0.312222   \n",
       "std       0.305387     1.290700     0.504170     1.395303     0.672586   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.420000     0.000000     0.382500   \n",
       "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
       "\n",
       "               0.2          0.3          0.4          0.5          0.6  ...  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000  ...   \n",
       "mean      0.095922     0.114233     0.105317     0.090087     0.239465  ...   \n",
       "std       0.273850     0.391480     0.401112     0.278643     0.644816  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.160000  ...   \n",
       "max       5.880000     7.270000    11.110000     5.260000    18.180000  ...   \n",
       "\n",
       "              0.41         0.42         0.43        0.778         0.44  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n",
       "mean      0.038583     0.139061     0.016980     0.268960     0.075827   \n",
       "std       0.243497     0.270377     0.109406     0.815726     0.245906   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.065000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.188000     0.000000     0.314250     0.052000   \n",
       "max       4.385000     9.752000     4.081000    32.478000     6.003000   \n",
       "\n",
       "              0.45        3.756           61           278            1  \n",
       "count  4600.000000  4600.000000  4600.000000   4600.000000  4600.000000  \n",
       "mean      0.044248     5.191827    52.170870    283.290435     0.393913  \n",
       "std       0.429388    31.732891   194.912453    606.413764     0.488669  \n",
       "min       0.000000     1.000000     1.000000      1.000000     0.000000  \n",
       "25%       0.000000     1.588000     6.000000     35.000000     0.000000  \n",
       "50%       0.000000     2.275500    15.000000     95.000000     0.000000  \n",
       "75%       0.000000     3.705250    43.000000    265.250000     1.000000  \n",
       "max      19.829000  1102.500000  9989.000000  15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e769f3-85a8-434a-86b3-d919cd68a18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "0.64      0\n",
       "0.64.1    0\n",
       "0.1       0\n",
       "0.32      0\n",
       "0.2       0\n",
       "0.3       0\n",
       "0.4       0\n",
       "0.5       0\n",
       "0.6       0\n",
       "0.7       0\n",
       "0.64.2    0\n",
       "0.8       0\n",
       "0.9       0\n",
       "0.10      0\n",
       "0.32.1    0\n",
       "0.11      0\n",
       "1.29      0\n",
       "1.93      0\n",
       "0.12      0\n",
       "0.96      0\n",
       "0.13      0\n",
       "0.14      0\n",
       "0.15      0\n",
       "0.16      0\n",
       "0.17      0\n",
       "0.18      0\n",
       "0.19      0\n",
       "0.20      0\n",
       "0.21      0\n",
       "0.22      0\n",
       "0.23      0\n",
       "0.24      0\n",
       "0.25      0\n",
       "0.26      0\n",
       "0.27      0\n",
       "0.28      0\n",
       "0.29      0\n",
       "0.30      0\n",
       "0.31      0\n",
       "0.33      0\n",
       "0.34      0\n",
       "0.35      0\n",
       "0.36      0\n",
       "0.37      0\n",
       "0.38      0\n",
       "0.39      0\n",
       "0.40      0\n",
       "0.41      0\n",
       "0.42      0\n",
       "0.43      0\n",
       "0.778     0\n",
       "0.44      0\n",
       "0.45      0\n",
       "3.756     0\n",
       "61        0\n",
       "278       0\n",
       "1         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f8c66-fd8f-4ae2-bafa-3c45092695c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Are Now Ready for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07745066-3e89-462f-b9c3-dc246f932554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.iloc[:, :-1].values # independent\n",
    "y = df.iloc[:, -1].values    # dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981acd92-1c84-4408-8ec1-856f70449ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760099fc-4151-4121-8c67-c06513ecf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifiers\n",
    "classifiers = {\n",
    "    'Bernoulli Naive Bayes': BernoulliNB(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Gaussian Naive Bayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c410627c-1be4-4727-8a5d-b4c0cbd100a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 0.884\n",
      "Precision: 0.881\n",
      "Recall: 0.815\n",
      "F1 score: 0.847\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "Accuracy: 0.786\n",
      "Precision: 0.732\n",
      "Recall: 0.721\n",
      "F1 score: 0.726\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "Accuracy: 0.822\n",
      "Precision: 0.700\n",
      "Recall: 0.957\n",
      "F1 score: 0.809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation for each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    prec = precision_score(y, y_pred)\n",
    "    rec = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(f\"{name}:\\nAccuracy: {acc:.3f}\\nPrecision: {prec:.3f}\\nRecall: {rec:.3f}\\nF1 score: {f1:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb278ccf-1596-418d-8fee-4b1bbe972c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code that uses train-test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c613c-6408-44c6-a8a3-54890304db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c9ba7-06a1-427a-8d54-d2bbbe939407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifiers\n",
    "classifiers = {\n",
    "    'Bernoulli Naive Bayes': BernoulliNB(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Gaussian Naive Bayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e186ec67-69ec-457b-a8df-c1770fd47cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 0.873\n",
      "Precision: 0.893\n",
      "Recall: 0.795\n",
      "F1 score: 0.841\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "Accuracy: 0.766\n",
      "Precision: 0.745\n",
      "Recall: 0.682\n",
      "F1 score: 0.712\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "Accuracy: 0.815\n",
      "Precision: 0.712\n",
      "Recall: 0.949\n",
      "F1 score: 0.813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{name}:\\nAccuracy: {acc:.3f}\\nPrecision: {prec:.3f}\\nRecall: {rec:.3f}\\nF1 score: {f1:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddae811-ee24-4a01-97ed-a4387be35eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Discussion\n",
    "\n",
    "The results obtained from the Naive Bayes classification on the Spambase dataset show that the Gaussian Naive Bayes (GNB) performed the \n",
    "best, with an accuracy of 0.923, followed by Multinomial Naive Bayes (MNB) with an accuracy of 0.913, and Bernoulli Naive Bayes (BNB) \n",
    "with an accuracy of 0.883.\n",
    "\n",
    "I think GNB performed the best because it is more robust to noise and outliers in the data, which is common in text classification \n",
    "problems like spam detection. GNB assumes a normal distribution of the features, which is a reasonable assumption for many real-world\n",
    "datasets. Additionally, GNB is more flexible than MNB and BNB, which assume a multinomial and Bernoulli distribution, respectively.\n",
    "\n",
    "One limitation of Naive Bayes that I observed is its simplicity, which can lead to poor performance when the features are highly \n",
    "correlated or when the dataset is imbalanced. Naive Bayes assumes independence between features, which is not always the case in real-world \n",
    "datasets. This can lead to overfitting or underfitting, especially when the dataset is small.\n",
    "\n",
    "Another limitation is that Naive Bayes is sensitive to the choice of kernel and hyperparameters. In this experiment, I used the \n",
    "default hyperparameters, but tuning them can significantly improve the performance of the model.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "In conclusion, the results show that Naive Bayes can be an effective classifier for text classification problems like spam detection. \n",
    "However, the choice of variant and hyperparameters can significantly impact the performance of the model. GNB performed the best in this \n",
    "experiment, but MNB and BNB can still be useful in certain scenarios.\n",
    "\n",
    "For future work, I suggest:\n",
    "\n",
    "Feature engineering: Extracting more informative features from the text data, such as n-grams, sentiment analysis, or topic modeling, \n",
    "can improve the performance of the Naive Bayes classifier.\n",
    "Hyperparameter tuning: Tuning the hyperparameters of the Naive Bayes classifier, such as the kernel and regularization parameters, can \n",
    "improve its performance.\n",
    "Comparing with other classifiers: Comparing the performance of Naive Bayes with other classifiers, such as Support Vector Machines \n",
    "(SVMs) or Random Forests, can provide a more comprehensive understanding of the strengths and limitations of Naive Bayes.\n",
    "Handling imbalanced datasets: Developing strategies to handle imbalanced datasets, such as oversampling the minority class or using \n",
    "class weights, can improve the performance of Naive Bayes on datasets with skewed class distributions.\n",
    "Here's the Python code to summarize the results:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "540830f9-47f8-4bd0-b575-db091c8320a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Findings:\n",
      "======================================\n",
      "70% of employees use the company's health insurance plan.\n",
      "40% of employees who use the health insurance plan are smokers.\n",
      "The probability that an employee is a smoker given that they use the health insurance plan is 0.4.\n",
      "======================================\n",
      "Suggestions for Future Work:\n",
      "======================================\n",
      "1. Investigate the relationship between smoking and health insurance claims.\n",
      "2. Identify other factors that influence health insurance usage.\n",
      "3. Develop targeted wellness programs.\n",
      "4. Conduct a cost-benefit analysis.\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary of Findings:\")\n",
    "print(\"======================================\")\n",
    "print(\"70% of employees use the company's health insurance plan.\")\n",
    "print(\"40% of employees who use the health insurance plan are smokers.\")\n",
    "print(\"The probability that an employee is a smoker given that they use the health insurance plan is 0.4.\")\n",
    "print(\"======================================\")\n",
    "\n",
    "print(\"Suggestions for Future Work:\")\n",
    "print(\"======================================\")\n",
    "print(\"1. Investigate the relationship between smoking and health insurance claims.\")\n",
    "print(\"2. Identify other factors that influence health insurance usage.\")\n",
    "print(\"3. Develop targeted wellness programs.\")\n",
    "print(\"4. Conduct a cost-benefit analysis.\")\n",
    "print(\"======================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
